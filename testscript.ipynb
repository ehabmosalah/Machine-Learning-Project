{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'label_encoders.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 580\u001b[0m\n\u001b[1;32m    578\u001b[0m loaded_objects \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m objects_to_load:\n\u001b[0;32m--> 580\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mobj\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    581\u001b[0m         loaded_objects[obj\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m    583\u001b[0m \u001b[38;5;66;03m# Load and preprocess acquiring company data\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'label_encoders.pkl'"
     ]
    }
   ],
   "source": [
    "# ======================== IMPORTS ========================\n",
    "from collections import Counter\n",
    "from joblib import dump\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pycountry\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "COLUMN_ALIASES = {\n",
    "    'IPO Date': 'IPO',\n",
    "    'Went Public': 'IPO',\n",
    "    'Public Listing': 'IPO'\n",
    "}\n",
    "\n",
    "def ensure_ipo(df):\n",
    "    df.rename(columns=COLUMN_ALIASES, inplace=True)\n",
    "    if 'IPO' not in df.columns:\n",
    "        df['IPO'] = np.nan\n",
    "    return df\n",
    "# ======================== CLASSES ========================\n",
    "class CorrelationFilter:\n",
    "    def __init__(self, threshold=0.85):\n",
    "        self.threshold = threshold\n",
    "        self.to_drop = set()  # Stores columns to drop\n",
    "        self.fitted = False   # Tracks if fit() was called\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"Identifies highly correlated columns to drop.\"\"\"\n",
    "        numerical_data = data.select_dtypes(include=[np.number])\n",
    "        corr_matrix = numerical_data.corr()\n",
    "\n",
    "        self.to_drop = set()  # Reset in case fit() is called again\n",
    "\n",
    "        for i in range(len(corr_matrix.columns)):\n",
    "            for j in range(i):\n",
    "                if abs(corr_matrix.iloc[i, j]) > self.threshold:\n",
    "                    colname = corr_matrix.columns[i]\n",
    "                    self.to_drop.add(colname)\n",
    "\n",
    "        self.fitted = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        \"\"\"Drops columns identified in fit().\"\"\"\n",
    "        if not self.fitted:\n",
    "            raise RuntimeError(\"Call fit() before transform()!\")\n",
    "        \n",
    "        cols_to_drop = list(self.to_drop & set(data.columns))\n",
    "        return data.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        \"\"\"Combines fit() and transform().\"\"\"\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "\n",
    "    def get_columns_to_drop(self):\n",
    "        \"\"\"Returns the list of columns to be dropped.\"\"\"\n",
    "        if not self.fitted:\n",
    "            raise RuntimeError(\"Call fit() first!\")\n",
    "        return list(self.to_drop)\n",
    "    \n",
    "class CategoryReducer:\n",
    "    def __init__(self, category_columns, top_n=15):\n",
    "        self.category_columns = category_columns\n",
    "        self.top_n = top_n\n",
    "        self.top_categories = None  # Will store the top categories from training\n",
    "\n",
    "    def fit(self, data):\n",
    "        # Identify and store the top N categories (only during training)\n",
    "        self.top_categories = (\n",
    "            data[self.category_columns]\n",
    "            .sum()\n",
    "            .sort_values(ascending=False)\n",
    "            .head(self.top_n)\n",
    "            .index.tolist()\n",
    "        )\n",
    "        return self  # For sklearn compatibility\n",
    "\n",
    "    def transform(self, data):\n",
    "        if self.top_categories is None:\n",
    "            raise RuntimeError(\"Call fit() before transform()!\")\n",
    "\n",
    "        # Keep only the top categories (from training)\n",
    "        df_top = data[self.top_categories].copy()\n",
    "\n",
    "        # Sum remaining categories into \"Other\"\n",
    "        other_columns = list(set(self.category_columns) - set(self.top_categories))\n",
    "        df_top['Other'] = data[other_columns].sum(axis=1).clip(upper=1)  # Ensures 0 or 1\n",
    "\n",
    "        # Drop original columns and concatenate reduced set\n",
    "        data = data.drop(columns=self.category_columns)\n",
    "        return pd.concat([data, df_top], axis=1)\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "\n",
    "    # Handle pickle compatibility\n",
    "    def __getstate__(self):\n",
    "        return {k: v for k, v in self.__dict__.items() \n",
    "                if k in ['category_columns', 'top_n', 'top_categories',\n",
    "                         'original_categories', 'expected_columns']}\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        self.__dict__.update(state)\n",
    "        # Initialize missing attributes for old versions\n",
    "        if not hasattr(self, 'original_categories'):\n",
    "            self.original_categories = self.category_columns\n",
    "        if not hasattr(self, 'expected_columns'):\n",
    "            self.expected_columns = (self.top_categories + ['Other'] \n",
    "                                     if self.top_categories else None)\n",
    "class AgeTransformer:\n",
    "    def __init__(self, current_year=2025):\n",
    "        self.current_year = current_year\n",
    "        self.age_mode = None\n",
    "        self.column_exists = True  # Track if column existed during training\n",
    "\n",
    "    def fit(self, data):\n",
    "        # Check if column exists in training data\n",
    "        if 'Year Founded' not in data.columns:\n",
    "            self.column_exists = False\n",
    "            return self\n",
    "            \n",
    "        data = data.copy()\n",
    "        data['Year Founded'] = pd.to_numeric(data['Year Founded'], errors='coerce')\n",
    "        data['age'] = self.current_year - data['Year Founded']\n",
    "        mode_series = data['age'].mode()\n",
    "        self.age_mode = mode_series[0] if not mode_series.empty else 5\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        \"\"\"Handle missing 'Year Founded' column gracefully\"\"\"\n",
    "        data = data.copy()\n",
    "        \n",
    "        # Create column if it doesn't exist\n",
    "        if 'Year Founded' not in data.columns:\n",
    "            if self.column_exists:\n",
    "                # Column existed in training but missing in new data\n",
    "                data['Year Founded'] = np.nan\n",
    "            else:\n",
    "                # Column never existed (new scenario)\n",
    "                data['age'] = self.age_mode\n",
    "                return data\n",
    "                \n",
    "        # Original processing if column exists\n",
    "        data['Year Founded'] = pd.to_numeric(data['Year Founded'], errors='coerce')\n",
    "        data['age'] = self.current_year - data['Year Founded']\n",
    "        data.drop(columns=['Year Founded'], inplace=True, errors='ignore')\n",
    "        data['age'].fillna(self.age_mode, inplace=True)\n",
    "        return data\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "class IPOAgeTransformer:\n",
    "    def __init__(self, current_year=2025, unknown_placeholder=\"Unknown\"):\n",
    "        self.current_year = current_year\n",
    "        self.unknown_placeholder = unknown_placeholder  # Replace NaN values\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"Stateless (no training needed). For pipeline compatibility.\"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        \"\"\"Computes IPO age and replaces missing values.\"\"\"\n",
    "        # if 'IPO' not in data.columns:\n",
    "        #     raise ValueError(\"Column 'IPO' not found in data.\")\n",
    "\n",
    "        df = data.copy()\n",
    "        df = ensure_ipo(df)\n",
    "        df['IPO'] = pd.to_numeric(df['IPO'], errors='coerce')\n",
    "        \n",
    "        # Compute age (clamp negative values to 0)\n",
    "        df['age IPO'] = (self.current_year - df['IPO']).clip(lower=0)\n",
    "        \n",
    "        # Replace missing ages with placeholder\n",
    "        df['age IPO'] = df['age IPO'].replace(\n",
    "            np.nan, self.unknown_placeholder\n",
    "        )\n",
    "        \n",
    "        # Drop original IPO column\n",
    "        df.drop(columns=['IPO'], inplace=True, errors='ignore')\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        return self.transform(data)  # fit() is stateless\n",
    "    \n",
    "class EmployeeDataCleaner:\n",
    "    def __init__(self):\n",
    "        self.employee_mode = None\n",
    "        self.mean_without_zeros = None\n",
    "        self.fitted = False  # Safety flag\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"Compute and store statistics from training data.\"\"\"\n",
    "        # Validate columns\n",
    "        required_columns = [\n",
    "            'Number of Employees (year of last update)',\n",
    "            'Number of Employees'\n",
    "        ]\n",
    "        for col in required_columns:\n",
    "            if col not in data.columns:\n",
    "                raise ValueError(f\"Column '{col}' not found in data.\")\n",
    "\n",
    "        # Compute mode for 'Number of Employees (year of last update)'\n",
    "        mode_series = data['Number of Employees (year of last update)'].mode()\n",
    "        self.employee_mode = mode_series[0] if not mode_series.empty else 0\n",
    "\n",
    "        # Compute mean (excluding zeros/negatives) for 'Number of Employees'\n",
    "        non_zero_employees = data.loc[\n",
    "            data['Number of Employees'] > 0, 'Number of Employees'\n",
    "        ]\n",
    "        self.mean_without_zeros = non_zero_employees.mean()\n",
    "\n",
    "        # Fallback if all values are zero/NaN\n",
    "        if pd.isna(self.mean_without_zeros):\n",
    "            self.mean_without_zeros = data['Number of Employees'].median()  # or a global default\n",
    "\n",
    "        self.fitted = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        \"\"\"Apply cleaning using statistics from fit().\"\"\"\n",
    "        if not self.fitted:\n",
    "            raise RuntimeError(\"Call fit() before transform()!\")\n",
    "\n",
    "        df = data.copy()\n",
    "\n",
    "        # Fill missing values with training mode\n",
    "        if 'Number of Employees (year of last update)' in df.columns:\n",
    "            df['Number of Employees (year of last update)'].fillna(\n",
    "                self.employee_mode, inplace=True\n",
    "            )\n",
    "\n",
    "        # Handle nulls/negatives and replace zeros with training mean\n",
    "        if 'Number of Employees' in df.columns:\n",
    "            df['Number of Employees'] = np.where(\n",
    "                df['Number of Employees'].isna() | (df['Number of Employees'] < 0),\n",
    "                0,\n",
    "                df['Number of Employees']\n",
    "            )\n",
    "            df['Number of Employees'] = df['Number of Employees'].replace(\n",
    "                0, self.mean_without_zeros\n",
    "            )\n",
    "\n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        return self.fit(data).transform(data)\n",
    "\n",
    "class BoardMembersTransformer:\n",
    "    def __init__(self, min_count=5):\n",
    "        self.min_count = min_count  # Keep only members appearing ≥ min_count times\n",
    "        self.common_members = None  # Stores frequent members from training\n",
    "        self.member_counts_ = None  # Optional: track raw counts\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"Identify frequently occurring board members from training data.\"\"\"\n",
    "        if 'Board Members' not in data.columns:\n",
    "            raise ValueError(\"Column 'Board Members' not found in data.\")\n",
    "\n",
    "        all_members = []\n",
    "        for cell in data['Board Members'].dropna():\n",
    "            members = [name.strip() for name in str(cell).split(',')]\n",
    "            all_members.extend(members)\n",
    "\n",
    "        # Count occurrences and filter by min_count\n",
    "        self.member_counts_ = Counter(all_members)\n",
    "        self.common_members = {\n",
    "            name for name, count in self.member_counts_.items() \n",
    "            if count >= self.min_count\n",
    "        }\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        \"\"\"Convert board members into binary features for common members.\"\"\"\n",
    "        if self.common_members is None:\n",
    "            raise RuntimeError(\"Call fit() before transform()!\")\n",
    "\n",
    "        df = data.copy()\n",
    "        \n",
    "        # Create binary columns for each common member\n",
    "        for member in self.common_members:\n",
    "            df[f'Board Member: {member}'] = df['Board Members'].apply(\n",
    "                lambda x: 1 if pd.notna(x) and member in str(x) else 0\n",
    "            )\n",
    "\n",
    "        # Optional: Add a summary feature (total members or binary \"has members\")\n",
    "        df['Has Board Members'] = df['Board Members'].notna().astype(int)\n",
    "        \n",
    "        # Drop original column\n",
    "        df.drop(columns=['Board Members'], inplace=True, errors='ignore')\n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        return self.fit(data).transform(data)\n",
    "\n",
    "class BoardMembersTransformer:\n",
    "    def __init__(self, min_count=5):\n",
    "        self.min_count = min_count  # Keep only members appearing ≥ min_count times\n",
    "        self.common_members = None  # Stores frequent members from training\n",
    "        self.member_counts_ = None  # Optional: track raw counts\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"Identify frequently occurring board members from training data.\"\"\"\n",
    "        if 'Board Members' not in data.columns:\n",
    "            raise ValueError(\"Column 'Board Members' not found in data.\")\n",
    "\n",
    "        all_members = []\n",
    "        for cell in data['Board Members'].dropna():\n",
    "            members = [name.strip() for name in str(cell).split(',')]\n",
    "            all_members.extend(members)\n",
    "\n",
    "        # Count occurrences and filter by min_count\n",
    "        self.member_counts_ = Counter(all_members)\n",
    "        self.common_members = {\n",
    "            name for name, count in self.member_counts_.items() \n",
    "            if count >= self.min_count\n",
    "        }\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        \"\"\"Convert board members into binary features for common members.\"\"\"\n",
    "        if self.common_members is None:\n",
    "            raise RuntimeError(\"Call fit() before transform()!\")\n",
    "\n",
    "        df = data.copy()\n",
    "        \n",
    "        # Create binary columns for each common member\n",
    "        for member in self.common_members:\n",
    "            df[f'Board Member: {member}'] = df['Board Members'].apply(\n",
    "                lambda x: 1 if pd.notna(x) and member in str(x) else 0\n",
    "            )\n",
    "\n",
    "        # Optional: Add a summary feature (total members or binary \"has members\")\n",
    "        df['Has Board Members'] = df['Board Members'].notna().astype(int)\n",
    "        \n",
    "        # Drop original column\n",
    "        df.drop(columns=['Board Members'], inplace=True, errors='ignore')\n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        return self.fit(data).transform(data)\n",
    "\n",
    "class FoundersTransformer:\n",
    "    def __init__(self, min_count=3):\n",
    "        self.min_count = min_count  # Keep founders appearing ≥ min_count times\n",
    "        self.common_founders = None  # Stores frequent founders from training\n",
    "        self.founder_counts_ = None  # Optional: track raw counts\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"Identify frequently occurring founders from training data.\"\"\"\n",
    "        if 'Founders' not in data.columns:\n",
    "            raise ValueError(\"Column 'Founders' not found in data.\")\n",
    "\n",
    "        all_founders = []\n",
    "        for cell in data['Founders'].dropna():\n",
    "            founders = [name.strip() for name in str(cell).split(',')]\n",
    "            all_founders.extend(founders)\n",
    "\n",
    "        # Count occurrences and filter by min_count\n",
    "        self.founder_counts_ = Counter(all_founders)\n",
    "        self.common_founders = {\n",
    "            name for name, count in self.founder_counts_.items() \n",
    "            if count >= self.min_count\n",
    "        }\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        \"\"\"Convert founders into binary features for common founders.\"\"\"\n",
    "        if self.common_founders is None:\n",
    "            raise RuntimeError(\"Call fit() before transform()!\")\n",
    "\n",
    "        df = data.copy()\n",
    "        \n",
    "        # Create binary columns for each common founder\n",
    "        for founder in self.common_founders:\n",
    "            df[f'Founder: {founder}'] = df['Founders'].apply(\n",
    "                lambda x: 1 if pd.notna(x) and founder in str(x) else 0\n",
    "            )\n",
    "\n",
    "        # Optional: Add a summary feature\n",
    "        df['Has Founders'] = df['Founders'].notna().astype(int)\n",
    "        \n",
    "        # Drop original column\n",
    "        df.drop(columns=['Founders'], inplace=True, errors='ignore')\n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        return self.fit(data).transform(data)\n",
    "\n",
    "class TaglineCategoryGuesser:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.category_keywords = {'Artificial Intelligence': ['ai', 'machine learning', 'deep learning', 'neural network'], 'Mobile': ['mobile', 'android', 'ios', 'app store', 'smartphone'], 'E-Commerce': ['ecommerce', 'e-commerce', 'shopping', 'online store'], 'FinTech': ['finance', 'banking', 'payments', 'fintech', 'crypto', 'blockchain'], 'Healthcare': ['health', 'medical', 'hospital', 'doctor', 'pharma'], 'Social Media': ['social network', 'community', 'messaging', 'chat'], 'Gaming': ['game', 'gaming', 'video game', 'esports'], 'Cloud': ['cloud', 'saas', 'paas', 'infrastructure'], 'EdTech': ['education', 'learning', 'students', 'teaching', 'school'], 'Data Analytics': ['analytics', 'data science', 'big data', 'insights']}\n",
    "\n",
    "    def guess_category_from_tagline(self, tagline):\n",
    "        tagline = str(tagline).lower()\n",
    "        matched = [cat for (cat, keywords) in self.category_keywords.items() if any((keyword in tagline for keyword in keywords))]\n",
    "        if len(matched) == 0:\n",
    "            matched = ['Software', 'Advertising']\n",
    "        elif len(matched) == 1:\n",
    "            matched.append('Software')\n",
    "        return ', '.join(matched)\n",
    "\n",
    "    def fit(self, data):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        df = data.copy()\n",
    "        df['Tagline'] = df['Tagline'].fillna('')\n",
    "        df['Market Categories'] = df['Market Categories'].fillna('Unknown')\n",
    "        df['Market Categories'] = df.apply(lambda row: self.guess_category_from_tagline(row['Tagline']) if str(row['Market Categories']).strip().lower() in ['unknown', 'nan', 'none', ''] else row['Market Categories'], axis=1)\n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        return self.fit(data).transform(data)\n",
    "class MarketCategoryGeneralizer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.category_mapping = {'Software': 'Technology & Software', 'Advertising': 'Advertising & Marketing', 'E-Commerce': 'E-Commerce & Online Services', 'Mobile': 'Mobile & Consumer Electronics', 'Games': 'Games & Entertainment', 'Social Media': 'Social Networking & Communication', 'Cloud': 'Technology & Software', 'Finance': 'Finance & Payments', 'Healthcare': 'Healthcare & Wellness', 'Semiconductors': 'Technology Hardware', 'Data Analytics': 'Analytics & Data Science', 'Search': 'Advertising & Marketing', 'Video': 'Games & Entertainment', 'Networking': 'Telecom & Networks', 'Messaging': 'Social Networking & Communication', 'Education': 'Education & Learning', 'News': 'Media & News', 'Photo Sharing': 'Digital Media & Content', 'Mobile Payments': 'Finance & Payments', 'Robotics': 'Games & Entertainment', 'Music': 'Games & Entertainment', 'Photo Editing': 'Digital Media & Content', 'Online Rental': 'E-Commerce & Online Services', 'Location Based Services': 'Telecom & Networks', 'Enterprise Software': 'Technology & Software', 'Video Streaming': 'Games & Entertainment', 'PaaS': 'Technology & Software', 'SaaS': 'Technology & Software', 'Health and Wellness': 'Healthcare & Wellness', 'Web Hosting': 'Technology & Software', 'Internet of Things': 'IoT (Internet of Things)', 'Cloud Security': 'Technology & Software', 'Virtual Currency': 'Finance & Payments', 'Search Marketing': 'Advertising & Marketing', 'Mobile Social': 'Social Networking & Communication', 'Retail': 'Retail & Fashion', 'Consulting': 'Others & Miscellaneous', 'Aerospace': 'Others & Miscellaneous', 'Food Delivery': 'Consumer Goods & Services', 'Fashion': 'Retail & Fashion', 'Wine And Spirits': 'Consumer Goods & Services', 'Streaming': 'Games & Entertainment', 'Task Management': 'Others & Miscellaneous', 'Video Chat': 'Social Networking & Communication', 'Personalization': 'Advertising & Marketing', 'Shopping': 'E-Commerce & Online Services', 'Local': 'E-Commerce & Online Services', 'News': 'Media & News', 'Fraud Detection': 'Advertising & Marketing', 'Image Recognition': 'Technology Hardware', 'Virtualization': 'Games & Entertainment', 'Analytics': 'Analytics & Data Science', 'Video on Demand': 'Games & Entertainment', 'Mobile Payments': 'Finance & Payments', 'Marketing Automation': 'Advertising & Marketing', 'Consumer Electronics': 'Mobile & Consumer Electronics', 'Video Games': 'Games & Entertainment', 'Public Relations': 'Advertising & Marketing'}\n",
    "\n",
    "    def map_categories(self, row):\n",
    "        categories = str(row).split(',')\n",
    "        generalized = []\n",
    "        for cat in categories:\n",
    "            cat = cat.strip()\n",
    "            if cat in self.category_mapping:\n",
    "                generalized.append(self.category_mapping[cat])\n",
    "            else:\n",
    "                generalized.append('Others & Miscellaneous')\n",
    "        return ', '.join(set(generalized))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "        df['Generalized Market Categories'] = df['Market Categories'].fillna('').apply(self.map_categories)\n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y).transform(X)\n",
    "class CountryRegionFiller:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.countries = [country.name for country in pycountry.countries]\n",
    "        self.regions = ['California', 'New York', 'Texas', 'Basel', 'Utah', 'Île-de-France', 'Bavaria', 'Ontario', 'Switzerland', 'United States', 'France', 'Great Britain', 'Israel', 'Sweden', 'Canada', 'Germany', 'Japan', 'India', 'Denmark', 'China', 'Spain', 'Netherlands', 'Finland', 'Australia', 'Ireland', 'United Stats of AMerica', 'United Arab Emirates', 'Quebec']\n",
    "\n",
    "    def find_place(self, text, place_list):\n",
    "        for place in place_list:\n",
    "            if re.search('\\\\b' + re.escape(place) + '\\\\b', str(text)):\n",
    "                return place\n",
    "        return None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "        for (idx, row) in df[df['Country (HQ)'].isnull() | df['State / Region (HQ)'].isnull()].iterrows():\n",
    "            desc = row['Description']\n",
    "            if pd.isnull(desc):\n",
    "                continue\n",
    "            country = self.find_place(desc, self.countries)\n",
    "            region = self.find_place(desc, self.regions)\n",
    "            if pd.isnull(row['Country (HQ)']) and country:\n",
    "                df.at[idx, 'Country (HQ)'] = country\n",
    "            if pd.isnull(row['State / Region (HQ)']) and region:\n",
    "                df.at[idx, 'State / Region (HQ)'] = region\n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X).transform(X)\n",
    "class CategoricalFillerAndEncoder:\n",
    "\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.modes = {}\n",
    "        self.label_encoders = {}\n",
    "        self.label_maps = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for col in self.columns:\n",
    "            mode_val = X[col].mode()[0]\n",
    "            self.modes[col] = mode_val\n",
    "            le = LabelEncoder()\n",
    "            filled = X[col].fillna(mode_val).astype(str)\n",
    "            le.fit(filled)\n",
    "            self.label_encoders[col] = le\n",
    "            self.label_maps[col] = {label: i for (i, label) in enumerate(le.classes_)}\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "        for col in self.columns:\n",
    "            mode_val = self.modes[col]\n",
    "            label_map = self.label_maps[col]\n",
    "            df[col] = df[col].fillna(mode_val).astype(str)\n",
    "            df[col + '_LabelEncoded'] = df[col].map(lambda x: label_map.get(x, -1))\n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y).transform(X)\n",
    "class CustomEncoder(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.status_cols_ = None\n",
    "        self.terms_cols_ = None\n",
    "\n",
    "    def fit(self, df):\n",
    "        self.status_cols_ = df['Status'].unique()\n",
    "        self.terms_cols_ = df['Terms'].unique()\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        df = pd.get_dummies(df, columns=['Status'], drop_first=False)\n",
    "        df = pd.get_dummies(df, columns=['Terms'], drop_first=False)\n",
    "        if 'Terms_Cash, Stock' in df.columns:\n",
    "            cash_stock_mask = df['Terms_Cash, Stock'] == 1\n",
    "            df.loc[cash_stock_mask, 'Terms_Cash'] = 1\n",
    "            df.loc[cash_stock_mask, 'Terms_Stock'] = 1\n",
    "            df = df.drop('Terms_Cash, Stock', axis=1)\n",
    "        expected_cols = [f'Status_{s}' for s in self.status_cols_] + [f'Terms_{t}' for t in self.terms_cols_ if t != 'Cash, Stock']\n",
    "        for col in expected_cols:\n",
    "            if col not in df.columns:\n",
    "                df[col] = 0\n",
    "        return df[expected_cols]\n",
    "# Load all saved objects\n",
    "objects_to_load = [\n",
    "    'mlb_acquiring.pkl', 'correlation_filter.pkl', 'category_reducer_acquiring.pkl',\n",
    "    'Age_column_acquiring.pkl', 'ipo_transformer_acquiring.pkl', 'employee_cleaner_acquiring.pkl',\n",
    "    'board_members_transformer.pkl', 'founders_transformer.pkl', 'tfidf_acquiring.pkl',\n",
    "    'tagline_guesser_acquired.pkl', 'category_generalizer_acquired.pkl',\n",
    "    'country_region_filler_acquired.pkl', 'categorical_encoder_acquired.pkl',\n",
    "    'mlb_acquired.pkl', 'mode_acquisitions_imputer.pkl', 'final_scaler.pkl',\n",
    "    'final_pca.pkl', 'custom_acquisitions_encoder.pkl', 'label_encoders.pkl',\n",
    "    'selected_features.pkl'\n",
    "]\n",
    "\n",
    "loaded_objects = {}\n",
    "for obj in objects_to_load:\n",
    "    with open(f'{obj}', 'rb') as f:\n",
    "        loaded_objects[obj.split('.')[0]] = pickle.load(f)\n",
    "\n",
    "# Load and preprocess acquiring company data\n",
    "acquiring_df = pd.read_csv('data/Acquiring Tech Companies.csv')\n",
    "# Apply transformers in order (simplified for brevity)\n",
    "acquiring_df = loaded_objects['Age_column'].transform(acquiring_df)\n",
    "acquiring_df = loaded_objects['ipo_transformer'].transform(acquiring_df)\n",
    "# Continue with other transformers as in training, e.g., employee_cleaner, mlb_acquiring, etc.\n",
    "\n",
    "# Similarly preprocess acquired_df\n",
    "acquired_df = pd.read_csv('data/Acquired Tech Companies.csv')\n",
    "acquired_df = loaded_objects['tagline_guesser'].transform(acquired_df)\n",
    "# Continue with other transformers\n",
    "\n",
    "# Load test acquisitions data\n",
    "test_df = pd.read_csv('path_to_test_csv')  # User to provide path\n",
    "\n",
    "# Preprocess test_df\n",
    "with open('mode_acquisitions_imputer.pkl', 'rb') as f:\n",
    "    mode_values = pickle.load(f)\n",
    "for col, mode_val in mode_values.items():\n",
    "    if col in test_df.columns:\n",
    "        test_df[col].fillna(mode_val, inplace=True)\n",
    "\n",
    "# Apply custom encoder for Status and Terms\n",
    "test_df = loaded_objects['custom_acquisitions_encoder'].transform(test_df)\n",
    "\n",
    "# Extract date features\n",
    "test_df['Deal_date'] = pd.to_datetime(test_df['Deal announced on'], dayfirst=True, errors='coerce')\n",
    "test_df['Deal_day'] = test_df['Deal_date'].dt.day\n",
    "test_df['Deal_month'] = test_df['Deal_date'].dt.month\n",
    "test_df['Deal_dayofweek'] = test_df['Deal_date'].dt.dayofweek\n",
    "test_df.drop(columns=['Deal announced on', 'Deal_date'], inplace=True)\n",
    "\n",
    "# Merge with preprocessed company data\n",
    "def find_company_column(df):\n",
    "    for col in df.columns:\n",
    "        if \"company\" in col.lower():\n",
    "            return col\n",
    "    raise ValueError(\"No company name column found.\")\n",
    "\n",
    "company_col_acquired = find_company_column(acquired_df)\n",
    "test_df['Acquired Company'] = test_df['Acquired Company'].str.strip().str.lower()\n",
    "acquired_df[company_col_acquired] = acquired_df[company_col_acquired].str.strip().str.lower()\n",
    "test_df = test_df.merge(acquired_df, how='left', left_on='Acquired Company', right_on=company_col_acquired, suffixes=('', '_Acquired'))\n",
    "test_df.drop(columns=[company_col_acquired], inplace=True)\n",
    "\n",
    "company_col_acquiring = find_company_column(acquiring_df)\n",
    "test_df['Acquiring Company'] = test_df['Acquiring Company'].str.strip().str.lower()\n",
    "acquiring_df[company_col_acquiring] = acquiring_df[company_col_acquiring].str.strip().str.lower()\n",
    "test_df = test_df.merge(acquiring_df, how='left', left_on='Acquiring Company', right_on=company_col_acquiring, suffixes=('', '_Acquiring'))\n",
    "test_df.drop(columns=[company_col_acquiring], inplace=True)\n",
    "\n",
    "# Handle missing values post-merge\n",
    "for col in test_df.columns:\n",
    "    if col in mode_values:\n",
    "        test_df[col].fillna(mode_values[col], inplace=True)\n",
    "\n",
    "# Encode categorical columns\n",
    "with open('label_encoders.pkl', 'rb') as f:\n",
    "    label_encoders = pickle.load(f)\n",
    "for col in test_df.columns:\n",
    "    if col in label_encoders:\n",
    "        le = label_encoders[col]\n",
    "        test_df[col] = test_df[col].astype(str).map(lambda s: le.transform([s])[0] if s in le.classes_ else -1)\n",
    "\n",
    "# Select features\n",
    "with open('selected_features.pkl', 'rb') as f:\n",
    "    selected_features = pickle.load(f)\n",
    "selected_features.remove('Deal size class')  # Assuming it's included\n",
    "test_df = test_df[selected_features]\n",
    "\n",
    "# Scale and apply PCA\n",
    "scaler = loaded_objects['final_scaler']\n",
    "pca = loaded_objects['final_pca']\n",
    "test_scaled = scaler.transform(test_df)\n",
    "test_scaled = pd.DataFrame(test_scaled, columns=test_df.columns)\n",
    "test_pca = pca.transform(test_scaled)\n",
    "\n",
    "# Load model and predict\n",
    "with open('best_gb_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "predictions = model.predict(test_pca)\n",
    "\n",
    "# Output predictions\n",
    "test_df['predicted_class'] = predictions\n",
    "test_df.to_csv('predictions.csv', index=False)\n",
    "\n",
    "# If true labels are provided, calculate accuracy\n",
    "if 'Deal size class' in test_df.columns:\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    accuracy = accuracy_score(test_df['Deal size class'], predictions)\n",
    "    print(f\"Accuracy: {accuracy:.3f}\")\n",
    "    print(\"Note: R2 and MSE are regression metrics; for classification, accuracy is provided.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
